spider
======

spider project

这个小项目是用来在网上抓取各种网页文件的程序。使用了spring的框架来构建，网络部分则使用了纯java来实现


运行方式：在命令行下运行java -jar spider-0.0.1.jar
运行后程序会自动创建pages目录，所抓取的所有网页都保存在这个目录下

为了简化程序，当抛出异常时，程序会中止运行。但是有关数据会保存在ini.xml中，下次再使用这个配置文件可以继续抓取。

ini.xml为配置文件，必须存在
Exception.ex为错误记录文件，必须存在
Log.lg为日志文件，必须存在
以上三个文件少任何一个，运行时都会报错

ini.xml中从上至下标签依次代表
起始文档编号
可创建线程数
抓取入点
未抓取URL队列
已抓取URL队列

当程序中断后，两个队列内容会依次保存进上述标签中

警告：
线程数越多，抓取时间越长，当执行退出保存和断点续搜时就会越慢，并且在配置不高机器上还会死机（我的单核老机子就死过好几回）
所以建议谨慎配置线程数！！！！
